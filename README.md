# MachineLearningMethods

从SVM到神经网络-探索机器学习的起源和本质/Python

##

参考某位大佬的Repo [Machine-Learning-Session](https://github.com/shuhuai007/Machine-Learning-Session)

学习相关视频以及进行代码实践~

(不知道为啥，从2020年起，开始疯狂爱上GitHub~ 大概这就是开源的魅力...（虽然作为菜鸡，我好像在开心的灌水...))

学业原因，也看了有些深度学习的论文和代码了，CV和CG的都有，然而一直在空中楼阁，似乎从来没有认真探索过深度学习的起源。

这背后的一切究竟是怎样的**统计学原理**？为什么**神将网络这么好用**？**数学**在这里到底起着这怎样的作用？

于是我开始了这趟令人新奇又兴奋的旅程，探索事物的本质，看清背后的真相。

## SVM 支持向量机 support vector machine

SVM有三宝：间隔，对偶，核技巧。

### kernel function：

1、非线性带来高维转换

2、对偶表示带来内积



##BP神经网路

神经网络的话，BP算是特别初级的入门级别算法了。

[MatLab红酒案例](https://www.bilibili.com/video/BV1Jp4y1y7m6?from=search&seid=1164372499231397940)

《一种基于BP神经网络的车牌字符分类识别方法》-2005 计算机科学:

[知乎堆导]（https://zhuanlan.zhihu.com/p/24801814）

## 参考视频

[BP神经网路](https://www.bilibili.com/video/BV1A4411x76J?from=search&seid=1798921675238288346)


